{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "7e41ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80685860",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "82f4a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: build a frequency dictionary for each class from the strings below\n",
    "pos_tweet = \"I am happy because I am learning NLP\\nI am happy, not sad.\"\n",
    "neg_tweet = \"I am sad, I am not learning NLP\\n am sad, not happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "981953b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text normalization\n",
    "def preprocess(text, PATTERN = r\"[^A-Za-z\\s]\"):\n",
    "    \"\"\"\n",
    "    returns tokens using regex patten for filtering\n",
    "    default removes anything that isn't an upper or lower character or a whitespace \n",
    "    \"\"\"\n",
    "    # remove anything that isn't an upper or lower character or a whitespace \n",
    "    return re.sub(PATTERN, '', text).split()\n",
    "\n",
    "pos_tokens = preprocess(pos_tweet)\n",
    "neg_tokens = preprocess(neg_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "c7173455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocab\n",
    "vocab = list(set(pos_tokens + neg_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "528818e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create word freq dictionary\n",
    "def word_freq_dict(tokens, vocab):\n",
    "    word_freq_dict = dict(zip(vocab, np.zeros((len(vocab)), int)))\n",
    "    for token in tokens:\n",
    "        if token in word_freq_dict.keys():\n",
    "            word_freq_dict[token] += 1\n",
    "    return word_freq_dict\n",
    "\n",
    "neg_word_freq = word_freq_dict(neg_tokens, vocab)\n",
    "pos_word_freq = word_freq_dict(pos_tokens, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "3692230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataframe to specifications\n",
    "\n",
    "pos_freq_df = pd.DataFrame({'word':list(pos_word_freq.keys()),\n",
    "                            'freq':list(pos_word_freq.values())}).set_index('word')\n",
    "\n",
    "neg_freq_df = pd.DataFrame({'word':list(neg_word_freq.keys()),\n",
    "                            'freq':list(neg_word_freq.values())}).set_index('word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "41ae3c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq_pos</th>\n",
       "      <th>freq_neg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>because</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          freq_pos  freq_neg\n",
       "word                        \n",
       "because          1         0\n",
       "sad              1         2\n",
       "not              1         2\n",
       "am               3         3\n",
       "NLP              1         1\n",
       "happy            2         1\n",
       "I                3         2\n",
       "learning         1         1"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df = pd.merge(pos_freq_df, neg_freq_df, on='word', suffixes=('_pos', '_neg'))\n",
    "freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "0737421c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_pos</th>\n",
       "      <th>prob_neg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>because</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          prob_pos  prob_neg\n",
       "word                        \n",
       "because   0.076923  0.000000\n",
       "sad       0.076923  0.166667\n",
       "not       0.076923  0.166667\n",
       "am        0.230769  0.250000\n",
       "NLP       0.076923  0.083333\n",
       "happy     0.153846  0.083333\n",
       "I         0.230769  0.166667\n",
       "learning  0.076923  0.083333"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conditional probability table\n",
    "cond_prob_df = freq_df / freq_df.sum()\n",
    "cond_prob_df.columns = ['prob_pos', 'prob_neg']\n",
    "cond_prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "4c851aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# naive bayes inference\n",
    "# can't divide by zero\n",
    "math.prod(cond_prob_df.iloc[:,0] / cond_prob_df.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "fe3b3b33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_pos</th>\n",
       "      <th>prob_neg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>because</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am</th>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          prob_pos  prob_neg\n",
       "word                        \n",
       "because   0.095238      0.05\n",
       "sad       0.095238      0.15\n",
       "not       0.095238      0.15\n",
       "am        0.190476      0.20\n",
       "NLP       0.095238      0.10\n",
       "happy     0.142857      0.10\n",
       "I         0.190476      0.15\n",
       "learning  0.095238      0.10"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# naive bayes inference with Laplacian smoothing\n",
    "# add 1 to the numerator and the length of the vocabulary in the denonimator \n",
    "# you divide by the number of 1s you add...\n",
    "cond_prob_df_ls = (freq_df + 1) / (freq_df.sum() + len(vocab))\n",
    "cond_prob_df_ls.columns = ['prob_pos', 'prob_neg']\n",
    "cond_prob_df_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "d4b75ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2032699769398878"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.prod(cond_prob_df_ls.iloc[:,0] / cond_prob_df_ls.iloc[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f356bb",
   "metadata": {},
   "source": [
    "### Log Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "e2826054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood: 1.2032699769398878\n",
      "log likelihood: 0.1850428315481053\n"
     ]
    }
   ],
   "source": [
    "#likelihood = product( P(word|pos) / P(word|neg))\n",
    "cond_prob_df_ls['ratio'] = cond_prob_df_ls.iloc[:,0] / cond_prob_df_ls.iloc[:,1]\n",
    "\n",
    "# likelihood\n",
    "print(f\"likelihood: {math.prod(cond_prob_df_ls['ratio'])}\")\n",
    "\n",
    "# log likelihood (lambda is the log of the ratio)\n",
    "cond_prob_df_ls['lambda'] = np.log(cond_prob_df_ls['ratio'])\n",
    "print(f\"log likelihood: {cond_prob_df_ls['lambda'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ea0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if dataset is imbalanced, add the log prior to the log likelihood \n",
    "# log prior = log (P(pos) / P(neg)) # ratio of pos/neg class instances \n",
    "# (i.e. how likely is it to end in pos class?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
